An Electromagnetic Articulograph (EMA) is an apparatus used to measure the movement of the tongue
and lips during speech. The motion tracking using EMA is registered by attaching
small sensors on the surface of the articulators (e.g., tongue and lips). The spatial
accuracy of motion tracking using EMA AG500 is 0.5 mm (Yunusova et al. 2009).
This is the EMA dataset in [1] which contains data collected
from multiple native English native speakers producing 25 words. Twelve sensors
were used in data collection, each providing X, Y and Z time-series positions with a
sampling rate of 200 Hz. The sensors are located on the forehead,
tongue; from tip to back in the midline, lips and jaw. The three head sensors (Head
Center, Head Right, and Head Left) attached on a pair of glasses were used to calculate
head-independent movement of other sensors. Tongue sensors were named T1, T2,
T3, and T4, from tip to back. Of the total of 36 available dimensions, this data set includes just 9. 
For more details about the data collection procedure and
description, please refer to Wang et al. [1]. The data we used was from the website associated with [2] and is included in the problem zip.
Originally it was split into three sensors.
Relevant Papers
[1]Wang J, Balasubramanian A, Mojica de la Vega L, Green JR, Samal A, Prabhakaran B (2013) Word
recognition from continuous articulatory movement time-series data using symbolic representations.
In: ACL/ISCA interspeech workshop on speech and language processing for assistive technologies,
Grenoble, pp 119–127
[2] M. Shokoohi-YektaEmail B. HuHongxia J. Wang and E Keogh (2017) Generalizing DTW to the multi-dimensional case requires an adaptive approach.
Data Mining and Knowledge Discovery (31) 1, pp 1–31. https://sites.google.com/site/dtwadaptive/home