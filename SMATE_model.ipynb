{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generic_utils import *\n",
    "from utils.basic_modules import *\n",
    "from utils.UEA_utils import *\n",
    "\n",
    "import time, os, math\n",
    "import pydot, pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as ll\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from decimal import Decimal\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Conv2D, Conv3D, TimeDistributed\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, add, GaussianNoise, Lambda\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical, plot_model, multi_gpu_model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "\n",
    "class SMATE:\n",
    "    def __init__(self, L, data_dim, n_classes, label_size, unlabel_size, y_sup, sup_ratio, pool_step, d_prime):\n",
    "        self.L = L\n",
    "        self.data_dim = data_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.label_size = label_size\n",
    "        self.unlabel_size = unlabel_size\n",
    "        self.train_size = label_size + unlabel_size\n",
    "        self.y_sup = y_sup\n",
    "        self.sup_ratio = sup_ratio\n",
    "        self.pool_step = pool_step\n",
    "        self.d_prime = d_prime\n",
    "        \n",
    "    def build_model(self, style=\"step_1\"):\n",
    "        y_sup_oneHot = to_categorical(self.y_sup, num_classes=self.n_classes) # n_sup * n_class (one-hot encoding)\n",
    "        \n",
    "        # linear mapping to low-dimensional space\n",
    "\n",
    "        in_shape = (self.L, self.data_dim)  # the input shape of encoder\n",
    "        self.model_e = encoder_smate(in_shape, self.pool_step, self.d_prime)\n",
    "        #self.model_e = encoder_smate_rdp(in_shape, self.pool_step)\n",
    "        #self.model_e = encoder_smate_se(in_shape, self.pool_step)\n",
    "        \n",
    "        h = self.model_e.output # batch_size * L\n",
    "\n",
    "        # Init central class points\n",
    "\n",
    "        idx_sup = np.array(range(self.label_size))\n",
    "        h_sup = K.gather(h, idx_sup)\n",
    "        proto_list = []\n",
    "        for i in range(self.n_classes):\n",
    "            idx = np.where(self.y_sup == i)[0]\n",
    "            # compute the central point of each class\n",
    "            class_repr = K.mean(K.gather(h_sup, idx), axis=0, keepdims=True)  # 1 * L\n",
    "            proto_list.append(class_repr) # n_classes * L\n",
    "        h_proto = ll.Concatenate(axis=0)(proto_list) # n_classes * L\n",
    "\n",
    "        # Adjust central points\n",
    "        if style == \"step_2\" or style == \"step_3\":\n",
    "            dists_sup = euclidean_dist_mts(h_sup, h_proto) # n_sup * n_class\n",
    "            dists_sum = K.sum(dists_sup, axis=1, keepdims=True) # normalize 'dists'\n",
    "            dists_norm = dists_sup / dists_sum # n_sup * n_class (one-hot encoding)\n",
    "            proba_sup = 1 - dists_norm\n",
    "            proba_sup = multiply([y_sup_oneHot, proba_sup]) # # n_sup * n_class\n",
    "            proba_sup = Lambda(lambda p: K.max(p, keepdims=True))(proba_sup) # n_sup * 1\n",
    "\n",
    "            proto_list = []\n",
    "            for i in range(self.n_classes):\n",
    "                idx = np.where(self.y_sup == i)[0]\n",
    "                class_repr = multiply([K.gather(h_sup, idx), K.gather(proba_sup,idx)]) #n_idx * L\n",
    "                class_repr = K.sum(class_repr, axis=0, keepdims=True) # 1 * L\n",
    "                proto_list.append(class_repr) # n_classes * L\n",
    "            h_proto = ll.Concatenate(axis=0)(proto_list) # n_classes * L\n",
    "        \n",
    "        # Semi-supervised learning using unlabeled samples\n",
    "        if style == \"step_3\":\n",
    "            if self.sup_ratio != 1:\n",
    "                idx_unsup = self.label_size + np.array(range(self.unlabel_size))\n",
    "                h_unsup =K.gather(h, idx_unsup)\n",
    "\n",
    "                dists_unsup = euclidean_dist_mts(h_unsup, h_proto) # n_unsup * n_class \n",
    "                dists_sum = K.sum(dists_unsup, axis=1, keepdims=True) # normalize 'dists'\n",
    "                dists_norm = dists_unsup / dists_sum # n_sup * n_class (one-hot encoding)\n",
    "                proba_unsup = 1 - dists_norm # get proba. distribution\n",
    "\n",
    "                y_unsup_pseudo = K.argmax(dists_unsup, axis=1) # n_unsup * 1, get pseudo labels\n",
    "                y_unsup_pseudo_oneHot = K.one_hot(y_unsup_pseudo, num_classes=self.n_classes) # n_unsup * n_class (one-hot encoding)\n",
    "\n",
    "                proba_unsup = multiply([y_unsup_pseudo_oneHot, proba_unsup]) # # n_unsup * n_class, get probability over class\n",
    "                proba_unsup = K.transpose(proba_unsup) # n_class * n_unsup\n",
    "\n",
    "                proto_list = []\n",
    "                for i in range(self.n_classes):\n",
    "                    proba_i = K.gather(proba_unsup, np.array([i])) # 1 * n_unsup \n",
    "                    proba_i = K.transpose(proba_i) # n_unsup * 1\n",
    "                    class_repr = multiply([h_unsup, proba_i]) # n_usup * L\n",
    "                    class_repr = K.sum(class_repr, axis=0, keepdims=True) # 1 * L\n",
    "                    proto_list.append(class_repr) # n_classes * L\n",
    "                h_proto_unsup = ll.Concatenate(axis=0)(proto_list) # n_classes * L\n",
    "\n",
    "                # Adjust central points using unlabeled samples\n",
    "\n",
    "                weight_sup = self.label_size / self.train_size\n",
    "                weight_unsup = 1 - weight_sup\n",
    "                h_proto = add([weight_sup * h_proto,  weight_unsup * h_proto_unsup])\n",
    "\n",
    "        # Re-calculate the distance vector\n",
    "        dists_sup = euclidean_dist_mts(h_sup, h_proto) # n_sup * n_class\n",
    "        \n",
    "        # Define the auto-encoder models\n",
    "\n",
    "        model_e_d = decoder_smate(self.model_e, self.L, self.data_dim, self.pool_step)\n",
    "\n",
    "        # Reconstruction loss\n",
    "\n",
    "        mts_in = self.model_e.input# batch_size * L * D\n",
    "        mts_out = model_e_d.output\n",
    "\n",
    "\n",
    "        rec_size = min(mts_in.shape[1], mts_out.shape[1])\n",
    "        loss_rec = K.sqrt(K.sum(K.pow(mts_in[:, :rec_size, :] - mts_out[:, :rec_size, :], 2)) / self.train_size) # real value\n",
    "\n",
    "        # Regularization loss\n",
    "\n",
    "        dists_sum = K.sum(dists_sup, axis=1, keepdims=True) # normalize 'dists'\n",
    "        dists_norm = dists_sup / dists_sum # n_sup * n_class (one-hot encoding)\n",
    "        y_pred = 1 - dists_norm\n",
    "        loss_reg = K.sum(categorical_crossentropy(y_pred, y_sup_oneHot)) / self.label_size\n",
    "\n",
    "        #loss_train = loss_rec\n",
    "        loss_train = loss_rec + loss_reg\n",
    "        \n",
    "        model_e_d.add_loss(loss_train)\n",
    "        opt = Adam(learning_rate=1e-05) # defaut LR: 1e-5\n",
    "        model_e_d.compile(optimizer=opt)\n",
    "        #plot_model(model_e_d, show_shapes=True)\n",
    "        #model_e_d.summary()\n",
    "        self.model = model_e_d\n",
    "        \n",
    "    def fit(self, n_epochs, x_train, x_sup, x_unsup):\n",
    "        \n",
    "        print('n_epochs=%d, batch_size=%d, n_sup=%d, n_sup=%d, steps=%d' % (\n",
    "            n_epochs, self.train_size, self.label_size, self.unlabel_size, n_epochs))\n",
    "\n",
    "        mycallbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, min_delta=0.0001, mode = 'auto')\n",
    "        ]\n",
    "\n",
    "        #callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, min_delta=0.0001, mode = 'auto')\n",
    "        if self.sup_ratio == 1:\n",
    "            x_fit = x_train\n",
    "        else:\n",
    "            x_fit = np.concatenate((x_sup, x_unsup), axis=0)\n",
    "\n",
    "        self.model.fit(\n",
    "            x=x_fit,\n",
    "            y=None,\n",
    "            batch_size=self.train_size,\n",
    "            epochs=n_epochs,\n",
    "            verbose=1,\n",
    "            callbacks=mycallbacks,\n",
    "            validation_split=0,\n",
    "            validation_data=None,\n",
    "            shuffle=False,\n",
    "            class_weight=None,\n",
    "            sample_weight=None,\n",
    "            initial_epoch=0,\n",
    "            max_queue_size=10,\n",
    "            workers=1,\n",
    "            use_multiprocessing=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def predict(self, x_train, y_train, x_test, y_test):\n",
    "        h_train = self.model_e.predict(x_train)\n",
    "        h_test = self.model_e.predict(x_test)\n",
    "\n",
    "        h_train = np.reshape(h_train, (h_train.shape[0], h_train.shape[1]*h_train.shape[2]))\n",
    "        h_test = np.reshape(h_test, (h_test.shape[0], h_test.shape[1]*h_test.shape[2]))\n",
    "        \n",
    "        #SVM\n",
    "        clf_svc = svm.SVC(kernel='linear')\n",
    "        clf_svc.fit(h_train, y_train)\n",
    "        acc_svm = accuracy_score(y_test, clf_svc.predict(h_test))\n",
    "\n",
    "        clf_svc = svm.LinearSVC()\n",
    "        clf_svc.fit(h_train, y_train)\n",
    "        acc_svm_linear = accuracy_score(y_test, clf_svc.predict(h_test))\n",
    "        print('acc_svm is ', acc_svm, 'acc_svm_linear is ', acc_svm_linear)\n",
    "        \n",
    "    def predict_unsup(self, x_label, y_label, x_unlabel, x_test, y_test):\n",
    "        h_label = self.model_e.predict(x_label)\n",
    "        h_unlabel = self.model_e.predict(x_unlabel)\n",
    "        h_test = self.model_e.predict(x_test)\n",
    "        h_label = np.reshape(h_label, (h_label.shape[0], h_label.shape[1]*h_label.shape[2]))\n",
    "        h_unlabel = np.reshape(h_unlabel, (h_unlabel.shape[0], h_unlabel.shape[1]*h_unlabel.shape[2]))\n",
    "        h_test = np.reshape(h_test, (h_test.shape[0], h_test.shape[1]*h_test.shape[2]))\n",
    "        # compute class centroids\n",
    "        centroid_list = []\n",
    "        for i in range(self.n_classes):\n",
    "            idx = np.where(y_label == i)[0]\n",
    "            # compute the central point of each class\n",
    "            h_centroid = np.mean(h_label[idx], axis = 0, keepdims=True) # 1 * L\n",
    "            centroid_list.append(h_centroid) \n",
    "        h_centroid = np.concatenate(centroid_list, axis=0) # n_classes * L\n",
    "\n",
    "        y_unsups = []\n",
    "        for h_i in h_unlabel:\n",
    "            dist_array = np.sqrt(np.sum((h_i - h_centroid) ** 2, axis=0))\n",
    "            pseudo_label = np.argmax(dist_array)\n",
    "            y_unsups.append(pseudo_label)\n",
    "        y_unsup = np.array(y_unsups)\n",
    "        \n",
    "        y_sup_unsup = np.concatenate([y_label, y_unsup])\n",
    "        h_sup_unsup = np.concatenate([h_label, h_unlabel])\n",
    "        #SVM\n",
    "        clf_svc = svm.SVC(kernel='linear')\n",
    "        clf_svc.fit(h_sup_unsup, y_sup_unsup)\n",
    "        acc_svm = accuracy_score(y_test, clf_svc.predict(h_test))\n",
    "\n",
    "        clf_svc = svm.LinearSVC()\n",
    "        clf_svc.fit(h_sup_unsup, y_sup_unsup)\n",
    "        acc_svm_linear = accuracy_score(y_test, clf_svc.predict(h_test))\n",
    "        print('acc_svm is ', acc_svm, 'acc_svm_linear is ', acc_svm_linear)\n",
    "        \n",
    "    def predict_ssl(self, x_sup, y_sup, x_unsup, y_unsup, x_test, y_test):\n",
    "        \n",
    "        ls_model = LabelSpreading(kernel='knn', n_neighbors=5)\n",
    "        indices = np.arange(self.train_size)\n",
    "        unlabeled_indices = indices[x_sup.shape[0]:]\n",
    "        y_sup_unsup = np.concatenate([y_sup, y_unsup])\n",
    "        y_sup_unsup_train = np.copy(y_sup_unsup)\n",
    "        y_sup_unsup_train[unlabeled_indices] = -1\n",
    "        \n",
    "        x_fit = np.concatenate([x_sup, x_unsup], axis=0)\n",
    "        h_fit = self.model_e.predict(x_fit)\n",
    "        h_fit = np.reshape(h_fit, (h_fit.shape[0], h_fit.shape[1]*h_fit.shape[2]))\n",
    "        ls_model.fit(h_fit, y_sup_unsup_train)\n",
    "        y_unsup_pred = ls_model.transduction_[unlabeled_indices]\n",
    "\n",
    "        #print(\"LabelSpread Accuracy is \", accuracy_score(y_unsup, y_unsup_pred))\n",
    "        \n",
    "        h_test = self.model_e.predict(x_test)\n",
    "        h_test = np.reshape(h_test, (h_test.shape[0], h_test.shape[1]*h_test.shape[2]))\n",
    "        \n",
    "        #SVM\n",
    "        clf_svc = svm.SVC(kernel='linear')\n",
    "        y_fit_true = ls_model.transduction_\n",
    "        clf_svc.fit(h_fit, y_fit_true)\n",
    "        acc_svm = accuracy_score(y_test, clf_svc.predict(h_test))\n",
    "\n",
    "        clf_svc = svm.LinearSVC()\n",
    "        clf_svc.fit(h_fit, y_fit_true)\n",
    "        acc_svm_linear = accuracy_score(y_test, clf_svc.predict(h_test))\n",
    "        print('acc_svm is ', acc_svm, 'acc_svm_linear is ', acc_svm_linear)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
