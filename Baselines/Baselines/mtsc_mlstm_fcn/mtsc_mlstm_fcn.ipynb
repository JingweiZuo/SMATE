{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data format conversion for MLSTM-FCN\n",
    "===\n",
    "\n",
    "\n",
    "---\n",
    "Input\n",
    "---\n",
    "\n",
    "A single file contains all samples and their labels: ***L * (3 + D)***\n",
    "\n",
    "\n",
    "\n",
    "- 1st col: sample_id\n",
    "- 2nd col: timestamps\n",
    "- 3rd col: label\n",
    "- after the 4th col: mts vector with D dimensions   \n",
    "\n",
    "---\n",
    "Output\n",
    "---\n",
    "\n",
    "Two array-like variables\n",
    "\n",
    "- X : array with shape (n_ts, d, sz)\n",
    "        Sequence data.\n",
    "- y : array with shape (n_ts, 1)\n",
    "        Target labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = \"./datasets/multivariate/\"\n",
    "ds = \"ECG\"\n",
    "ds_train = ds + '/' + ds + \"_TRAIN3\"\n",
    "ds_test = ds + '/' + ds + \"_TEST3\"\n",
    "\n",
    "NB_CLASS = 0\n",
    "MAX_TIMESTEPS = 0\n",
    "MAX_NB_VARIABLES = 0\n",
    "\n",
    "def z_normalization(mts):\n",
    "    M = len(mts[0, :])\n",
    "    for i in range(M):\n",
    "        mts_i = mts[:, i]\n",
    "        mean = np.mean(mts_i)\n",
    "        std = np.std(mts_i)\n",
    "        mts_i = (mts_i - mean) / std\n",
    "        mts[:, i] = mts_i\n",
    "    return mts\n",
    "\n",
    "def convert_mts(rep, dataset, z_normal = False):\n",
    "    global NB_CLASS, MAX_NB_VARIABLES\n",
    "    \n",
    "    seq = np.genfromtxt(rep + dataset, delimiter=' ', dtype=str, encoding=\"utf8\")\n",
    "    \n",
    "    ids, counts = np.unique(seq[:,0], return_counts=True)\n",
    "    No = ids.shape[0]\n",
    "    D = seq.shape[1] - 3\n",
    "    arr = np.asarray((ids, counts)).T\n",
    "    Max_Seq_Len = np.max(arr[:,1].astype(np.int))\n",
    "    out_X = np.zeros((No, D, Max_Seq_Len))\n",
    "    out_Y = np.zeros((No, ))\n",
    "\n",
    "    classes = np.unique(seq[:,2])\n",
    "    NB_CLASS = classes.shape[0]\n",
    "    MAX_NB_VARIABLES = D\n",
    "    \n",
    "    for idx, id in enumerate(ids):\n",
    "        seq_cpy = seq[seq[:,0] == id]\n",
    "        l_seq = seq_cpy.shape[0]\n",
    "        out_X[idx, :, :l_seq] = np.transpose(seq_cpy[:, 3:])\n",
    "        out_Y[idx] = seq_cpy[0, 2] \n",
    "        if z_normal: \n",
    "            out_X[idx, :, :l_seq] = np.transpose(z_normalization(np.transpose(out_X[idx, :, :l_seq])))\n",
    "        \n",
    "    return out_X, out_Y\n",
    "\n",
    "def load_datasets(rep, ds_train, ds_test, z_normal = False):\n",
    "    global MAX_TIMESTEPS\n",
    "    X_train, y_train = convert_mts(rep, ds_train, z_normal)\n",
    "    X_test, y_test = convert_mts(rep, ds_test, z_normal)\n",
    "    if X_train.shape[-1] != X_test.shape[-1]:\n",
    "        MAX_TIMESTEPS = min(X_train.shape[-1], X_test.shape[-1])\n",
    "        X_train = X_train[:,:,:MAX_TIMESTEPS]\n",
    "        X_test = X_test[:,:,:MAX_TIMESTEPS]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset :  (100, 2, 147) (100,)\n",
      "Test dataset :  (100, 2, 147) (100,)\n",
      "Train dataset metrics :  5.437827059388522e-19 0.7833297148563118\n",
      "Test dataset :  -0.0005672631931700671 0.7767444333298086\n",
      "Nb classes :  2\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_datasets(rep, ds_train, ds_test, z_normal = True)\n",
    "\n",
    "# ''' Save the datasets '''\n",
    "print(\"Train dataset : \", X_train.shape, y_train.shape)\n",
    "print(\"Test dataset : \", X_test.shape, y_test.shape)\n",
    "print(\"Train dataset metrics : \", X_train.mean(), X_train.std())\n",
    "print(\"Test dataset : \", X_test.mean(), X_test.std())\n",
    "print(\"Nb classes : \", len(np.unique(y_train)))\n",
    "\n",
    "np.save(rep + ds + '/X_train.npy', X_train)\n",
    "np.save(rep + ds + '/y_train.npy', y_train)\n",
    "np.save(rep + ds + '/X_test.npy', X_test)\n",
    "np.save(rep + ds + '/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Build and train the Network Model\n",
    "===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
    "\n",
    "from utils.keras_utils import train_model, evaluate_model, set_trainable\n",
    "from utils.layer_utils import AttentionLSTM\n",
    "\n",
    "TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_model_2():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 10\n",
    "\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    #ip1 = K.reshape(ip,shape=(MAX_TIMESTEPS,MAX_NB_VARIABLES))\n",
    "    #x = Permute((2, 1))(ip)\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(128)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model\n",
    "\n",
    "def generate_model_3():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_model_4():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 3\n",
    "    #\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model\n",
    "\n",
    "def squeeze_excite_block(input):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    filters = input._keras_shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "    se = GlobalAveragePooling1D()(input)\n",
    "    se = Reshape((1, filters))(se)\n",
    "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = multiply([input, se])\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2, 147)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 147, 2)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 147, 128)     2176        permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 128)     512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 8)         1024        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 128)       1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 147, 128)     0           activation_1[0][0]               \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 147, 256)     164096      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 256)     1024        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 256)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 16)        4096        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 256)       4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 147, 256)     0           activation_2[0][0]               \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 147, 128)     98432       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 2, 147)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 128)     512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_lstm_1 (AttentionLSTM (None, 128)          252032      masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 128)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           attention_lstm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           dropout_1[0][0]                  \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            514         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 529,538\n",
      "Trainable params: 528,514\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  100 Number of test samples :  100\n",
      "Number of classes :  2\n",
      "Sequence length :  147\n",
      "X_train.shape is  (100, 2, 147)\n",
      "X_test.shape is  (100, 2, 147)\n",
      "Class weights :  [1.47058824 0.75757576]\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 100 samples, validate on 100 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9889dbc5d552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDATASET_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_INDEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_INDEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/SMATGAN/Baselines/mtsc_mlstm_fcn/utils/keras_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset_id, dataset_prefix, dataset_fold_id, epochs, batch_size, val_subset, cutoff, normalize_timeseries, learning_rate, monitor, optimization_mode, compile_model)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callback_list,\n\u001b[0;32m--> 162\u001b[0;31m               class_weight=class_weight, verbose=2, validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3287\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m         session != self._session):\n\u001b[0;32m-> 3289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   3220\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1444\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1446\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1447\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = generate_model_2()\n",
    "\n",
    "DATASET_INDEX = rep + ds + '/'\n",
    "\n",
    "train_model(model, DATASET_INDEX, dataset_prefix=ds+'_', epochs=1000, batch_size=128)\n",
    "\n",
    "evaluate_model(model, DATASET_INDEX, dataset_prefix=ds+'_', batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
