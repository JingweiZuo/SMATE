{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.generic_utils import *\n",
    "import time, functools\n",
    "\n",
    "NB_CLASS = 0\n",
    "MAX_TIMESTEPS = 0\n",
    "MAX_NB_VARIABLES = 0\n",
    "\n",
    "def z_normalization(mts):\n",
    "    M = len(mts[0, :])\n",
    "    for i in range(M):\n",
    "        mts_i = mts[:, i]\n",
    "        mean = np.mean(mts_i)\n",
    "        std = np.std(mts_i)\n",
    "        mts_i = (mts_i - mean) / std\n",
    "        mts[:, i] = mts_i\n",
    "    return mts\n",
    "\n",
    "def convert_mts(rep, dataset, z_normal = False):\n",
    "    global NB_CLASS, MAX_NB_VARIABLES\n",
    "    \n",
    "    seq = np.genfromtxt(rep + dataset, delimiter=' ', dtype=str, encoding=\"utf8\")\n",
    "    \n",
    "    ids, counts = np.unique(seq[:,0], return_counts=True)\n",
    "    No = ids.shape[0]\n",
    "    D = seq.shape[1] - 3\n",
    "    arr = np.asarray((ids, counts)).T\n",
    "    Max_Seq_Len = np.max(arr[:,1].astype(np.int))\n",
    "    out_X = np.zeros((No, D, Max_Seq_Len))\n",
    "    out_Y = np.zeros((No, ))\n",
    "\n",
    "    classes = np.unique(seq[:,2])\n",
    "    NB_CLASS = classes.shape[0]\n",
    "    MAX_NB_VARIABLES = D\n",
    "    \n",
    "    for idx, id in enumerate(ids):\n",
    "        seq_cpy = seq[seq[:,0] == id]\n",
    "        l_seq = seq_cpy.shape[0]\n",
    "        out_X[idx, :, :l_seq] = np.transpose(seq_cpy[:, 3:])\n",
    "        out_Y[idx] = seq_cpy[0, 2] \n",
    "        if z_normal: \n",
    "            out_X[idx, :, :l_seq] = np.transpose(z_normalization(np.transpose(out_X[idx, :, :l_seq])))\n",
    "        \n",
    "    return out_X, out_Y\n",
    "\n",
    "def load_datasets(rep, ds_train, ds_test, z_normal = False):\n",
    "    global MAX_TIMESTEPS\n",
    "    \n",
    "    \n",
    "    X_train, y_train = convert_mts(rep, ds_train, z_normal)\n",
    "    X_test, y_test = convert_mts(rep, ds_test, z_normal)\n",
    "    \n",
    "    # Normalize labels to [0, n_class]\n",
    "    Y_train = np.zeros(len(y_train))\n",
    "    Y_test = np.zeros(len(y_test))\n",
    "    \n",
    "    classes, counts_cl = np.unique(y_train, return_counts=True)\n",
    "    print(\"class list is \" + str(classes))\n",
    "\n",
    "    mapping_c_l = {}  # a mappling between classes and labels\n",
    "    for idx, c in enumerate(list(classes)):\n",
    "        mapping_c_l.update({c: idx})\n",
    "    \n",
    "    i = 0\n",
    "    for c in y_train:  # get keras labels\n",
    "        Y_train[i] = mapping_c_l[c]\n",
    "        i = i + 1\n",
    "    i = 0\n",
    "    for c in y_test:  # get keras labels\n",
    "        Y_test[i] = mapping_c_l[c]\n",
    "        i = i + 1\n",
    "    \n",
    "    classes_norm, counts_cl_conv = np.unique(Y_train, return_counts=True)\n",
    "    print(\"class list (norm) is \" + str(classes_norm))\n",
    "    \n",
    "    if X_train.shape[-1] != X_test.shape[-1]:\n",
    "        MAX_TIMESTEPS = min(X_train.shape[-1], X_test.shape[-1])\n",
    "        X_train = X_train[:,:,:MAX_TIMESTEPS]\n",
    "        X_test = X_test[:,:,:MAX_TIMESTEPS]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "# split labeled and unlabeled dataset\n",
    "\n",
    "def split_dataset_train(X, Y, sup_ratio, strategy='RandomSplit'):\n",
    "    '''\n",
    "    Objective: by supervised ratio, split the samples for supervised and unsupervised training\n",
    "\n",
    "    :param X: a 3-D array: Nbr_samples x L x D\n",
    "    :param X_s: a 5-D array: Nbr_samples x L x D x D x Chl\n",
    "    :param masking: a 3-D array: Nbr_samples x L x 1\n",
    "    :param Y: an 1-D array\n",
    "    :param sup_ratio: the ratio of supervised samples\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    X_list_label, Y_list_label = list(), list()\n",
    "    X_list_unlabel, Y_list_unlabel = list(), list()\n",
    "\n",
    "    # compute the number of samples with labels to take\n",
    "    n_samples = int(sup_ratio * len(Y))\n",
    "    classes, counts_cl = np.unique(Y, return_counts=True)\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    if sup_ratio == 1:\n",
    "        return X, Y, np.array([]), np.array([]), n_classes\n",
    "    \n",
    "    if strategy == 'RandomSplit':\n",
    "\n",
    "        ## not equal-split between classes\n",
    "        idx_label = rd.sample(range(0, X.shape[0]), n_samples)\n",
    "        X_sup = X[idx_label]\n",
    "        Y_sup = Y[idx_label]\n",
    "        # put the rest of the samples in the class in unlabeled samples\n",
    "        idx_unlabel = np.array(range(len(Y)))  # the total number of instance in the class\n",
    "        idx_unlabel = np.ma.array(idx_unlabel, mask=False)\n",
    "        for i in idx_label:\n",
    "            idx_unlabel.mask[i] = True\n",
    "        idx_unlabel = idx_unlabel.compressed()  # a list of index for unlabeled samples\n",
    "\n",
    "        X_unsup = X[idx_unlabel]\n",
    "        Y_unsup = Y[idx_unlabel]\n",
    "\n",
    "        return X_sup, Y_sup, X_unsup, Y_unsup, n_classes\n",
    "\n",
    "    else:\n",
    "        ## equal-split between classes\n",
    "\n",
    "        n_per_class = int(n_samples / n_classes)\n",
    "        for c in classes:\n",
    "            idx_c = np.where(Y == c)[0]  # take an array without 'dtype'\n",
    "            # get all samples for this class\n",
    "            X_c = [X[i] for i in idx_c]\n",
    "            # choose random instances\n",
    "            if (n_per_class > len(X_c)):\n",
    "                idx_label = range(0, len(X_c))\n",
    "            else:\n",
    "                idx_label = rd.sample(range(0, len(X_c)), n_per_class)\n",
    "            X_label = [X_c[i] for i in idx_label]\n",
    "            X_list_label.extend(X_label)\n",
    "            Y_list_label.extend([c] * len(idx_label))\n",
    "\n",
    "            # put the rest of the samples in the class in unlabeled samples\n",
    "            new_idx_c = np.array(range(len(idx_c)))  # the total number of instance in the class\n",
    "            new_idx_c = np.ma.array(new_idx_c, mask=False)\n",
    "            for i in idx_label:\n",
    "                new_idx_c.mask[i] = True\n",
    "            idx_unlabel = new_idx_c.compressed()  # a list of index for unlabeled samples\n",
    "\n",
    "            X_unlabel = [X_c[i] for i in idx_unlabel]\n",
    "\n",
    "            X_list_unlabel.extend(X_unlabel)\n",
    "            Y_list_unlabel.extend([c] * len(idx_unlabel))\n",
    "\n",
    "            X_sup = np.array(X_list_label)\n",
    "            Y_sup = np.asarray(Y_list_label).flatten()\n",
    "\n",
    "            X_unsup = np.array(X_list_unlabel)\n",
    "            Y_unsup = np.asarray(Y_list_unlabel).flatten()\n",
    "\n",
    "        return X_sup, Y_sup, X_unsup, Y_unsup, n_classes\n",
    "    \n",
    "def get_PolluScope_dataset(rep, ds_train, ds_test, sup_ratio, split_strategy='EqualSplit'):\n",
    "    start = time.time()\n",
    "    X_train, X_test, Y_train, Y_test = load_datasets(rep, ds_train, ds_test, z_normal = True)\n",
    "    end_load = time.time()\n",
    "    print('time cost for loading data  : ' + str(end_load - start))\n",
    "    \n",
    "    X_sup, Y_sup, X_unsup, Y_unsup, n_classes = split_dataset_train(X_train, Y_train, sup_ratio, split_strategy)  # split the training set into labeled and unlabed samples\n",
    "    end_split = time.time()\n",
    "    print('time cost for splitting data  : ' + str(end_split - end_load))\n",
    "    \n",
    "    dataset = {}\n",
    "    dataset.update({'X_train': X_train})\n",
    "    dataset.update({'X_test': X_test})\n",
    "    dataset.update({'Y_train': Y_train})\n",
    "    dataset.update({'Y_test': Y_test})\n",
    "    dataset.update({'X_sup': X_sup})\n",
    "    dataset.update({'Y_sup': Y_sup})\n",
    "    dataset.update({'X_unsup': X_unsup})\n",
    "    dataset.update({'Y_unsup': Y_unsup})\n",
    "    dataset.update({'n_classes': n_classes})\n",
    "\n",
    "    return dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
